<h1>–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∏–∑–∞—Ü–∏—è</h1>
<h2>–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ4</h2>

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ1**

```
from pathlib import Path
import csv


def read_text(path: str | Path, encoding: str = "utf-8") -> str:
  
    path = Path(path)
    
    with open(path, 'r', encoding=encoding) as file:
        return file.read()


def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:

    path = Path(path)
    
    # –°–æ–∑–¥–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    ensure_parent_dir(path)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
    if rows:
        first_row_length = len(rows[0])
        for i, row in enumerate(rows):
            if len(row) != first_row_length:
                raise ValueError(f"–°—Ç—Ä–æ–∫–∞ {i} –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(row)}, –æ–∂–∏–¥–∞–µ—Ç—Å—è {first_row_length}")
    
    with open(path, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        
        if header is not None:
            writer.writerow(header)
        
        writer.writerows(rows)


def ensure_parent_dir(path: str | Path) -> None:
 
    path = Path(path)
    parent_dir = path.parent
    parent_dir.mkdir(parents=True, exist_ok=True)


if __name__ == "__main__":
    # –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã
    from io_txt_csv import read_text, write_csv
    
    # –¢–µ—Å—Ç –∑–∞–ø–∏—Å–∏ CSV
    write_csv([("word", "count"), ("test", 3)], "data/check.csv")
    
    # –¢–µ—Å—Ç —á—Ç–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (–µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    try:
        txt = read_text("test_input.txt")  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
        print("–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω")
    except FileNotFoundError:
        print("–§–∞–π–ª test_input.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except UnicodeDecodeError:
        print("–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞")
```
**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ2**
```

import sys
import argparse
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ lib –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
lib_path = Path(__file__).parent.parent.parent / 'lib'
sys.path.insert(0, str(lib_path))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö
from io_txt_csv import read_text, write_csv
from lib.text import normalize, tokenize, count_freq, top_n


def generate_report(input_path: str, output_path: str, encoding: str = "utf-8") -> None:
    
    # –ß—Ç–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    try:
        text = read_text(input_path, encoding)
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª '{input_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)
    except UnicodeDecodeError as e:
        print(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}")
        print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É —Å –ø–æ–º–æ—â—å—é --encoding")
        sys.exit(1)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ lib/text.py
    normalized_text = normalize(text, casefold=True, yo2e=True)
    tokens = tokenize(normalized_text)
    
    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç
    frequencies = count_freq(tokens)
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ - –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é —Å–ª–æ–≤–∞
    sorted_words = sorted(frequencies.items(), 
                         key=lambda x: (-x[1], x[0]))
    
    # –ó–∞–ø–∏—Å—å CSV
    header = ("word", "count")
    write_csv(sorted_words, output_path, header)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—é–º–µ –≤ –∫–æ–Ω—Å–æ–ª—å
    total_words = len(tokens)
    unique_words = len(frequencies)
    
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
    
    if unique_words > 0:
        top_5_words = top_n(frequencies, 5)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ lib/text.py
        print("–¢–æ–ø-5:")
        for i, (word, count) in enumerate(top_5_words, 1):
            print(f"  {i}. '{word}' - {count}")
    else:
        print("–¢–æ–ø-5: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
    
    print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"
    )
    parser.add_argument(
        "--in", 
        dest="input_file",
        default="test_input.txt",
        help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: test_input.txt)"
    )
    parser.add_argument(
        "--out",
        dest="output_file", 
        default="data/report.csv",
        help="–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: data/report.csv)"
    )
    parser.add_argument(
        "--encoding",
        default="utf-8",
        help="–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: utf-8)"
    )
    
    args = parser.parse_args()
    
    generate_report(args.input_file, args.output_file, args.encoding)


if __name__ == "__main__":
    main()
```

<h2>–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ3</h2>

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ1**

```
import re

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def tokenize(text: str) -> list[str]:
    return re.findall(r'\w+(?:-\w+)*', text)

def count_freq(tokens: list[str]) -> dict[str, int]:
    freq = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1 
    return freq


def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    sorted_freq = sorted(freq.items(), key=lambda item: (-item[1], item[0]))
    return sorted_freq[:n]
print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–∏—Ä\t"))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
print(count_freq(["a","b","a","c","b","a"]))
print(top_n(count_freq(["a","b","a","c","b","a"])))
print(top_n(count_freq(["bb","aa","bb","aa","cc"]), n=2))
```
![alt text](images/lab03/img.3.1.png)
**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ2**

```
import sys
from text import *

def text_info():
    text = sys.stdin.readline().strip()
    words = sorted(tokenize(normalize(text)), key=len, reverse=True)
    print(words)
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokenize(normalize(text)))}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokenize(normalize(text))))}")
    print("–¢–æ–ø-5:")
    print_word_frequency_table(text)
def print_word_frequency_table(text):
    freqs = count_freq(tokenize(normalize(text)))
    print('—Å–ª–æ–≤–æ'.ljust(12), '|', '—á–∞—Å—Ç–æ—Ç–∞')
    print('-' * 22)
    for word, count in sorted(freqs.items(), key=lambda x: x[1], reverse=True):
         print(word.ljust(12), '|', count)


text_info()
```
![alt text](images/lab03/img.3.2.png)


<h2>–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2</h2>

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ1**

```
#n=int(input('dlina:'))
#nums=[]
#i=0
#while i<n:
   # nums.append(input())
   # i+=1
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if not nums:
        raise ValueError("–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
    return(min(nums), max(nums))


def unique_sorted(nums: list[float | int]) -> list[float | int]:
    return sorted(set(nums))


def flatten(mat: list[list | tuple]) -> list:
    result = []
    for row in mat:
        if not isinstance(row, (list, tuple)):
            raise TypeError("–≠–ª–µ–º–µ–Ω—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂–µ–º")
        result.extend(row)
    return result
#print(min_max(nums))
print(min_max([3, -1, 5, 5, 0]))
print(min_max([42]))
print(min_max([-5, -2, -9]))
print(min_max([1.5, 2, 2.0, -3.1]))
#print(unique_sorted(nums))
print(unique_sorted([3, 1, 2, 1, 3]))
print(unique_sorted([]))
print(unique_sorted([-1, -1, 0, 2, 2]))
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))
print(flatten([[1, 2], [3, 4]]))
print(flatten(([1, 2], (3, 4, 5))))
print(flatten([[1], [], [2, 3]]))

#print(flatten([[1, 2], "ab"]))
#print(min_max([]))
```
![alt text](images/lab02/img.2.1.png)

–ü—Ä–∏ –≤–≤–µ–¥–µ–Ω–∏–∏:

print(flatten([[1, 2], "ab"]))

print(min_max([]))

–í—ã–≤–æ–¥

![alt text](images/lab02/img.2.1.1error.png)
![alt text](images/lab02/img.2.1.2error.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ2**

```
def check_rectangular(mat):
    if not mat:
        return True
    length = len(mat[0])
    for row in mat:
        if len(row) != length:
            return False
    return True


def transpose(mat):
    if not check_rectangular(mat):
        raise ValueError("–†–≤–∞–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")
    if not mat:
        return []
    return [list(row) for row in zip(*mat)]


def row_sums(mat):
    if not check_rectangular(mat):
        raise ValueError("–†–≤–∞–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")
    return [sum(row) for row in mat]


def col_sums(mat):
    if not check_rectangular(mat):
        raise ValueError("–†–≤–∞–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")
    if not mat:
        return []
    return [sum(col) for col in zip(*mat)]
print(transpose([[1, 2, 3]]))
print(transpose([[1], [2], [3]]))
print(transpose([[1, 2], [3, 4]]))
print(transpose([]))
#print(transpose([[1, 2], [3]]))

print(row_sums([[1, 2, 3], [4, 5, 6]]))
print(row_sums([[-1, 1], [10, -10]] ))
print(row_sums([[0, 0], [0, 0]]))
#print(row_sums([[1, 2], [3]]))

print(col_sums([[1, 2, 3], [4, 5, 6]]))
print(col_sums([[-1, 1], [10, -10]] ))
print(col_sums([[0, 0], [0, 0]]))
#print(col_sums([[1, 2], [3]]))
```
![alt text](images/lab02/img.2.2.png)


–ü—Ä–∏ –≤–≤–µ–¥–µ–Ω–∏–∏:

print(transpose([[1, 2], [3]]))

print(row_sums([[1, 2], [3]]))

print(col_sums([[1, 2], [3]]))

–í—ã–≤–æ–¥:
![alt text](images/lab02/img.2.2.1error.png)
![alt text](images/lab02/img.2.2.2error.png)
![alt text](images/lab02/img.2.2.3error.png)


**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ3**
```
from typing import Tuple

StudentRecord = Tuple[str, str, float]

def format_record(rec: StudentRecord) -> str:
    fio, group, gpa = rec
    fio_parts = [part.strip() for part in fio.split()]
    formatted_surname = fio_parts[0].capitalize()
    initials = ''.join([f'{name[0].upper()}.' for name in fio_parts[1:]])
    formatted_gpa = f'{gpa:.2f}'
    formatted_record = f"{formatted_surname} {initials}, –≥—Ä. {group}, GPA {formatted_gpa}"
    return formatted_record

print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.605)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)))
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))
#print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", 3.999)))
```
![alt text](images/lab02/img.2.3.png)

–ü—Ä–∏ –≤–≤–µ–¥–µ–Ω–∏–∏:

print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", 3.999)))

–í—ã–≤–æ–¥:
![alt text](images/lab02/img.2.3.error.png)



<h2>–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ1</h2>

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ1**

```
name=input("–ò–º—è: ")
age=int(input('–í–æ–∑—Ä–≤—Å—Ç: '))
print(f'–ü—Ä–∏–≤–µ—Ç {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age+1}!')
```
![alt text](images/lab01/img01.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ2**

```
a = input("a: ").replace(',', '.')
b = input("b: ").replace(',', '.')
a = float(a)
b = float(b)
_sum = a + b
_avg = _sum / 2
print(f"sum={_sum:.2f}; avg={_avg:.2f}")
```
![alt text](images/lab01/img02.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ3**
```
price=float(input())
discount=float(input())
vat=float(input())
base=price*(1-discount/100)
vat_amount=base*(vat/100)
total=base+vat_amount
print(f'–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏:{base:.2f}‚ÇΩ')
print(f'–ù–î–°:{vat_amount:.2f}‚ÇΩ')
print(f'–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:{total:.2f}‚ÇΩ')
```
![alt text](images/lab01/img03.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ4**
```
m=int(input('–º–∏–Ω—É—Ç—ã:'))
hours=m//60
minutes=m%60
print(f'{hours}:{minutes:02d}')
```
![alt text](images/lab01/img04.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ5**
```
a, b, c = input().split()
print(f"–§–ò–û: {a} {b} {c}")
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {a[0]}{b[0]}{c[0]}.")
print(f"–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {len(a) + len(b) + len(c) + 2}")
```
![alt text](images/lab01/img05.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ6**
```
N=int(input('in_1:'))
onsite=0
remote=0
for _ in range(N):
    count="in_"+str(_+2)+':'
    line=input(count).strip().split()
    surname,name,age,format_part=line
    if format_part=="True":
        onsite+=1
    else:
        remote+=1
print('out:',onsite, remote)
```
![alt text](images/lab01/img06.png)

**–ó–∞–¥–∞–Ω–∏–µ ‚Ññ7**
```
encoded= input('in:')
first_char_pos = 0
for i, char in enumerate(encoded):
    if 'A' <= char <= 'Z':
        first_char_pos = i
        first_char = char
        break
digit_position = 0
for i, char in enumerate(encoded):
    if char.isdigit():
        digit_position = i
        break
second_char = encoded[digit_position + 1]
step = digit_position + 1 - first_char_pos
result = first_char + second_char 
current_position = digit_position + 1 + step
while current_position < len(encoded) and encoded[current_position] != '.':
    result += encoded[current_position]
    current_position += step
result += "." 
print('out:',result)

```
![alt text](images/lab01/img07.png)